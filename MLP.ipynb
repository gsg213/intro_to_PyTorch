{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfMvDnOvOiVX"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github//gsg213/intro_to_PyTorch/blob/master/MLP.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzhBW6RBPRJF"
      },
      "source": [
        "from torch.optim import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_blobs\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR0TeJoHQRSL"
      },
      "source": [
        "Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_w5w7bDPVHU"
      },
      "source": [
        "def get_model(inFeatures=4, hiddenDim=8, nbClasses=3):\n",
        "\t\n",
        "  # build a sequential neural network based on input parameters\n",
        "\t\n",
        "  mlp_model = nn.Sequential(OrderedDict([\n",
        "\t\t(\"hidden_layer_1\", nn.Linear(inFeatures, hiddenDim)),\n",
        "\t\t(\"activation_1\", nn.ReLU()),\n",
        "\t\t(\"output_layer\", nn.Linear(hiddenDim, nbClasses))]))\n",
        "\n",
        "\t# return model\n",
        "  return mlp_model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxgBYOiMP58N"
      },
      "source": [
        "def next_batch(inputs, targets, batchSize):\n",
        "\t# loop over the dataset\n",
        "\tfor i in range(0, inputs.shape[0], batchSize):\n",
        "\t\t# yield a tuple of the current batched data and labels\n",
        "    #(return over iterations)\n",
        "\t\tyield (inputs[i:i + batchSize], targets[i:i + batchSize])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMZ54h3lX9hg",
        "outputId": "c44972fb-6335-4398-ae44-f89bee68ed72"
      },
      "source": [
        "# define batch size, epochs, and learning rate\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "LR = 1e-2\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Training using {}\".format(DEVICE))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training using cuda...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgtjy3LxYE9b",
        "outputId": "aa315d77-d785-4138-ef1f-299411d37faa"
      },
      "source": [
        "# generate a 3-class classification problem with 1000 data points,\n",
        "# where each data point is a 4D feature vector\n",
        "print(\"Preparing dataset\")\n",
        "X, y = make_blobs(n_samples=1000, n_features=4, centers=3, cluster_std=2.5, random_state=46)\n",
        "\n",
        "# create training and testing splits, and convert them to PyTorch tensors\n",
        "trainX, testX, trainY, testY = train_test_split(X, y,\ttest_size=0.15, random_state=46)\n",
        "trainX = torch.from_numpy(trainX).float()\n",
        "testX = torch.from_numpy(testX).float()\n",
        "trainY = torch.from_numpy(trainY).float()\n",
        "testY = torch.from_numpy(testY).float()\n",
        "print(\"train size: {}\".format(trainX.shape))\n",
        "print(\"train size: {}\".format(trainY.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing dataset\n",
            "train size: torch.Size([850, 4])\n",
            "train size: torch.Size([850])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0g1DQzMYi7L",
        "outputId": "1ee62fac-dcf2-49e7-93cd-bf7afb0bc00f"
      },
      "source": [
        "# initialize model and display its architecture\n",
        "#get_model(inFeatures=4, hiddenDim=8, nbClasses=3)\n",
        "input_features = trainX.shape[1]\n",
        "hidden_neurons = 12\n",
        "output_classes = 3\n",
        "\n",
        "mlp = get_model(inFeatures=input_features, hiddenDim= hidden_neurons, nbClasses=output_classes).to(DEVICE)\n",
        "print(mlp)\n",
        "\n",
        "# initialize optimizer and loss function\n",
        "opt = SGD(mlp.parameters(), lr=LR)\n",
        "lossFunc = nn.CrossEntropyLoss()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (hidden_layer_1): Linear(in_features=4, out_features=12, bias=True)\n",
            "  (activation_1): ReLU()\n",
            "  (output_layer): Linear(in_features=12, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiQcBiuyPkH5"
      },
      "source": [
        "Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpncezoqa89k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5a4b16-450a-485d-d0e4-5092b1be285b"
      },
      "source": [
        "\n",
        "train_message = \"epoch: {} test loss: {:.3f} test accuracy: {:.3f}\"\n",
        "# loop through the epochs\n",
        "for epoch in range(0, EPOCHS):\n",
        "\t# initialize tracker variables and set our model to trainable\n",
        "\tprint(\"epoch: {}\".format(epoch + 1))\n",
        "\ttrainLoss = 0\n",
        "\ttrainAcc = 0\n",
        "\tsamples = 0\n",
        "\tmlp.train()\n",
        "\t# loop over the current batch of data\n",
        "\tfor (batchX, batchY) in next_batch(trainX, trainY, BATCH_SIZE):\n",
        "\t\t# flash data to the current device, run it through our\n",
        "\t\t# model, and calculate loss\n",
        "\t\t(batchX, batchY) = (batchX.to(DEVICE), batchY.to(DEVICE))\n",
        "\t\tpredictions = mlp(batchX)\n",
        "\t\tloss = lossFunc(predictions, batchY.long())\n",
        "\t\t# zero the gradients accumulated from the previous steps,\n",
        "\t\t# perform backpropagation, and update model parameters\n",
        "\t\topt.zero_grad()\n",
        "\t\tloss.backward()\n",
        "\t\topt.step()\n",
        "\t\t# update training loss, accuracy, and the number of samples\n",
        "\t\t# visited\n",
        "\t\ttrainLoss += loss.item() * batchY.size(0)\n",
        "\t\ttrainAcc += (predictions.max(1)[1] == batchY).sum().item()\n",
        "\t\tsamples += batchY.size(0)\n",
        "\t# display model progress on the current training batch\n",
        "\ttrainTemplate = \"epoch: {} train loss: {:.3f} train accuracy: {:.3f}\"\n",
        "\tprint(trainTemplate.format(epoch + 1, (trainLoss / samples),\n",
        "\t\t(trainAcc / samples)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1\n",
            "epoch: 1 train loss: 0.877 train accuracy: 0.622\n",
            "epoch: 2\n",
            "epoch: 2 train loss: 0.380 train accuracy: 0.940\n",
            "epoch: 3\n",
            "epoch: 3 train loss: 0.234 train accuracy: 0.972\n",
            "epoch: 4\n",
            "epoch: 4 train loss: 0.173 train accuracy: 0.976\n",
            "epoch: 5\n",
            "epoch: 5 train loss: 0.140 train accuracy: 0.978\n",
            "epoch: 6\n",
            "epoch: 6 train loss: 0.120 train accuracy: 0.979\n",
            "epoch: 7\n",
            "epoch: 7 train loss: 0.106 train accuracy: 0.979\n",
            "epoch: 8\n",
            "epoch: 8 train loss: 0.096 train accuracy: 0.979\n",
            "epoch: 9\n",
            "epoch: 9 train loss: 0.088 train accuracy: 0.979\n",
            "epoch: 10\n",
            "epoch: 10 train loss: 0.082 train accuracy: 0.980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_TevLKnPoTN"
      },
      "source": [
        "Test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh_QctM4PYYx",
        "outputId": "6a0a475c-2d6c-4d65-bc9a-e302861d8043"
      },
      "source": [
        "\t# initialize tracker variables for testing, then set our model to\n",
        "\t# evaluation mode\n",
        "\ttestLoss = 0\n",
        "\ttestAcc = 0\n",
        "\tsamples = 0\n",
        "\tmlp.eval()\n",
        "\t# initialize a no-gradient context, this doesn't aloow to modify the weights\n",
        "\twith torch.no_grad():\n",
        "\t\t# loop over the current batch of test data\n",
        "\t\tfor (batchX, batchY) in next_batch(testX, testY, BATCH_SIZE):\n",
        "\t\t\t# flash the data to the current device\n",
        "\t\t\t(batchX, batchY) = (batchX.to(DEVICE), batchY.to(DEVICE))\n",
        "\t\t\t# run data through our model and calculate loss\n",
        "\t\t\tpredictions = mlp(batchX)\n",
        "\t\t\tloss = lossFunc(predictions, batchY.long())\n",
        "\t\t\t# update test loss, accuracy, and the number of\n",
        "\t\t\t# samples visited\n",
        "\t\t\ttestLoss += loss.item() * batchY.size(0)\n",
        "\t\t\ttestAcc += (predictions.max(1)[1] == batchY).sum().item()\n",
        "\t\t\tsamples += batchY.size(0)\n",
        "\t\t# display model progress on the current test batch\n",
        "\t\ttestTemplate = \"epoch: {} test loss: {:.3f} test accuracy: {:.3f}\"\n",
        "\t\tprint(testTemplate.format(epoch + 1, (testLoss / samples),\n",
        "\t\t\t(testAcc / samples)))\n",
        "\t\tprint(\"\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 10 test loss: 0.067 test accuracy: 0.993\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvn2zHBC8HQi"
      },
      "source": [
        "Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCwq49qOPmIi"
      },
      "source": [
        "torch.save(mlp.state_dict(),'tensor.pt')\n",
        "#mlp.state_dict()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kzLX1lE8Jre"
      },
      "source": [
        "Loading the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTGH-K-q7mLW",
        "outputId": "914fd599-a929-44d2-d9c7-6d409ff60fd7"
      },
      "source": [
        "model = get_model(inFeatures=input_features, hiddenDim= hidden_neurons, nbClasses=output_classes).to(DEVICE)\n",
        "model.load_state_dict(torch.load('tensor.pt'))\n",
        "model.eval()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (hidden_layer_1): Linear(in_features=4, out_features=12, bias=True)\n",
              "  (activation_1): ReLU()\n",
              "  (output_layer): Linear(in_features=12, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s8_hdvu8iY5",
        "outputId": "8cc1ca2c-835a-4cb8-e3b8-0afd91cc8943"
      },
      "source": [
        "\t# initialize a no-gradient context, this doesn't aloow to modify the weights\n",
        "\twith torch.no_grad():\n",
        "\t\t# loop over the current batch of test data\n",
        "\t\tfor (batchX, batchY) in next_batch(testX, testY, BATCH_SIZE):\n",
        "\t\t\t# flash the data to the current device\n",
        "\t\t\t(batchX, batchY) = (batchX.to(DEVICE), batchY.to(DEVICE))\n",
        "\t\t\t# we use the loaded model\n",
        "\t\t\tpredictions = model(batchX)\n",
        "\t\t\tloss = lossFunc(predictions, batchY.long())\n",
        "\t\t\t# update test loss, accuracy, and the number of\n",
        "\t\t\t# samples visited\n",
        "\t\t\ttestLoss += loss.item() * batchY.size(0)\n",
        "\t\t\ttestAcc += (predictions.max(1)[1] == batchY).sum().item()\n",
        "\t\t\tsamples += batchY.size(0)\n",
        "\t\t# display model progress on the current test batch\n",
        "\t\ttestTemplate = \"epoch: {} test loss: {:.3f} test accuracy: {:.3f}\"\n",
        "\t\tprint(testTemplate.format(epoch + 1, (testLoss / samples),\n",
        "\t\t\t(testAcc / samples)))\n",
        "\t\tprint(\"\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 10 test loss: 0.067 test accuracy: 0.993\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szZkQOj589ce"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}