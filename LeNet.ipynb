{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LeNet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMfdUEHAYKEuwgiepoERuVF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ClHZyA-MX1ro"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github//gsg213/intro_to_PyTorch/blob/master/LeNet.ipynb)"]},{"cell_type":"code","metadata":{"id":"URbcOWjkBjk6"},"source":["# import the necessary packages\n","from torch.nn import Module\n","from torch.nn import Conv2d\n","from torch.nn import Linear\n","from torch.nn import MaxPool2d\n","from torch.nn import ReLU\n","from torch.nn import LogSoftmax\n","from torch import flatten"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"03hApcJQEJbU"},"source":["Network initialization and forward"]},{"cell_type":"code","metadata":{"id":"Oj_KxBDPB1Ni"},"source":["class LeNet(Module):\n","\tdef __init__(self, numChannels, classes):\n","\t\t\n","\t\tsuper(LeNet, self).__init__()\n","\t\t\n","    #intitialize first conv layer\n","\t\tself.conv1 = Conv2d(in_channels=numChannels, out_channels=20, kernel_size=(5, 5))\n","\t\t\n","    #just created once as the layers are the same\n","    self.relu = ReLU()\n","\t\tself.maxpool = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n","  \n","\t\t#initialize second conv layer\n","\t\tself.conv2 = Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5))\n","\t\t\n","    #initialize FC\n","\t\tself.fc1 = Linear(in_features=800, out_features=500)\n","\t\t\n","\t\t#initialize softmax classifier\n","\t\tself.fc2 = Linear(in_features=500, out_features=classes)\n","\t\tself.logSoftmax = LogSoftmax(dim=1)\n","\n","\tdef forward(self, x):\n","\t\tx = self.conv1(x)\n","\t\tx = self.relu(x)\n","\t\tx = self.maxpool(x)\n","\n","\t\tx = self.conv2(x)\n","\t\tx = self.relu(x)\n","\t\tx = self.maxpool(x)\n","\n","\t\tx = flatten(x, 1)\n","\t\tx = self.fc1(x)\n","\t\tx = self.relu(x)\n","\n","\t\tx = self.fc2(x)\n","\t\toutput = self.logSoftmax(x)\n","\n","\t\treturn output"],"execution_count":null,"outputs":[]}]}